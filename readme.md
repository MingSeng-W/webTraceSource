##  微博舆情溯源方案流程的思路：

 1.第一步把要溯源的微博文本进行关键字提取，我这个采用的是终端交互的方式文本的方式（也可以读取文件）

 2.第二步：处理文体提取关键字，提取出来的影响后面结果的准确性，我测了关键词在3，4个左右能够测得比较准一些。

 3.第三步：模拟登陆微博获得cookie（在account文件里存取多个账号密码，获取多个cookie,用于以后的多账号并行爬取数据）构建带有cookie的请求头。

 4.第四步：把关键字放到搜索栏中经行爬取内容，获得用户的id,名称。

 5.第五步：把爬下来的数据进行文本处理，比如说去掉表情之类的，然后和溯源文本进行相似度比对，这里准备采用判断文本的余弦夹角得到相似度。（好难，我期初用了把整个文本进行分词，然后去两个文本的交集与原文本的关系，得到相似度），得到相似度之后，把这条微博（包含各种信息，时间，用户id等等）和相似度存到数据库中。

 6.第六步：在数据库中得到数据之后，  通过查询文本相似度和时间这两个作为查询关键，这有个相似度阈值的设置问题，设多大的相似度合适，这是一个需要进行讨论的问题。通过查到最早时间，相似度大于某个值的，返回5条微博，人工进行判断，我测试过目前有误差的范围不是很大，但是无法完全做到机器准确判断。不太清楚怎么做，实验老师又不提供思路，只是给个微博溯源大方向（泪流满面。。。）

## 数据库的设计
数据库表的设计:
关于新浪微博溯源的主要有博主的名称,博主的id,微博的id,他的父节点的微博id,和他的子节点的微博id,时间,转发量,主页链接


爬取方法:
1.给定微博,首先判断改微博是否为转发的微博,如果是的话,那么就进行下一步的解析;如果不是的话,那么就丢弃
判断微博是否为转发的算法:
    1判断用户的转发消息中是否有@,然后进行取舍

   try:
        next=div.contians('@')
        print "this is a repost weibo"
   except:
         print 'this is a original weibo'

2.分析微博的结构,找出weibo的id,现在转发weibo博主的id,用户名,爬取的上一个博主的id,用户名,最后再查出来源博主的微博.



### 2016/9/11日,获得最后的时间
1.首先获得搜索的关键词检索出来的关键词,的totalpage
2.跳到totalpage的那一页,找出最后的时间
3.判读totalpage的页数是否为50页,如果为50页,那么就拿到时间,然后,做一个以时间为关键词的搜索
4.这时候应该设置一个flag,判断flag,得到循环结束的条件

### 2017/7/17日
	由于比较忙，得空的话我会把整个方案的思路重新讲清楚，以及每个模块的作用（python小白哈，边百度边写的，主要是重在实现整个方案），这个新浪的模拟登陆功能好久没有进行调试了，模拟登陆的是把新浪3g web的网页,取cookie..后面调试了补上。整个流程逻辑还是大致应该不变的。


